apiVersion: v1
kind: ServiceAccount
metadata:
  name: spark-operator
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: edit-resources
rules:
- apiGroups: [""]
  resources: ["pods", "replicationcontrollers", "services", "configmaps"]
  verbs: ["create", "delete", "deletecollection", "get", "list", "update", "watch", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: spark-operator-edit-resources
roleRef:
  kind: Role
  name: edit-resources
  apiGroup: ""
subjects:
  - kind: ServiceAccount
    name: spark-operator
---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: spark-operator
  labels: &default-labels
    app.kubernetes.io/name: spark-operator
    app.kubernetes.io/version: v0.3.6-v1alpha1
spec:
  replicas: 1
  selector:
    matchLabels: *default-labels
  strategy:
    type: Recreate
  template:
    metadata:
      labels: *default-labels
    spec:
      serviceAccountName: spark-operator
      containers:
      - name: spark-operator
        image: quay.io/radanalyticsio/spark-operator:latest-released
        env:
        - name: CRD # if false, the operator will watch on ConfigMaps
          value: "false"
        #- name: WATCH_NAMESPACE # if not specified the same ns as the operator's will be used, use * for all (+ set cluster rights)
        #  value: "default"
        #- name: FULL_RECONCILIATION_INTERVAL_S
        #  value: "180"
        #- name: CRD # if false, the operator will watch on ConfigMaps
        #  value: "true"
        #- name: METRICS # should we expose metrics for Prometheus?
        #  value: "false"
        #- name: METRICS_PORT
        #  value: "8080"
        #- name: METRICS_JVM # should we expose also internal JVM metrics?
        #  value: "false"
        #- name: COLORS
        #  value: "false"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
        imagePullPolicy: IfNotPresent

